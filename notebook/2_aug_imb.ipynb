{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f6bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ca01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "aug_synonym = naw.SynonymAug(aug_src='wordnet', aug_min=1, aug_max=3)\n",
    "\n",
    "aug_insert = naw.SynonymAug(aug_src='wordnet', aug_min=1, aug_max=2, aug_p=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f22e8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AUGMENTING MINORITY CLASSES\n",
      "============================================================\n",
      "\n",
      "Augmentation targets:\n",
      "  • Neutral class:  3,091 → 9,157 (need 6,066 more)\n",
      "  • Positive class: 2,353 → 9,157 (need 6,804 more)\n",
      "\n",
      "⏳ Augmenting neutral class...\n",
      "   Processed 500/6066...\n",
      "   Processed 1000/6066...\n",
      "   Processed 1500/6066...\n",
      "   Processed 2000/6066...\n",
      "   Processed 2500/6066...\n",
      "   Processed 3000/6066...\n",
      "   Processed 3500/6066...\n",
      "   Processed 4000/6066...\n",
      "   Processed 4500/6066...\n",
      "   Processed 5000/6066...\n",
      "   Processed 5500/6066...\n",
      "   Processed 6000/6066...\n",
      "✓ Neutral class augmented: 6066 new samples\n",
      "\n",
      "⏳ Augmenting positive class...\n",
      "   Processed 500/6804...\n",
      "   Processed 1000/6804...\n",
      "   Processed 1500/6804...\n",
      "   Processed 2000/6804...\n",
      "   Processed 2500/6804...\n",
      "   Processed 3000/6804...\n",
      "   Processed 3500/6804...\n",
      "   Processed 4000/6804...\n",
      "   Processed 4500/6804...\n",
      "   Processed 5000/6804...\n",
      "   Processed 5500/6804...\n",
      "   Processed 6000/6804...\n",
      "   Processed 6500/6804...\n",
      "✓ Positive class augmented: 6804 new samples\n"
     ]
    }
   ],
   "source": [
    "def augment_text(text, augmenter, num_augmentations=1):\n",
    "    augmented_texts = []\n",
    "    for _ in range(num_augmentations):\n",
    "        try:\n",
    "            aug_text = augmenter.augment(text)\n",
    "            if aug_text and aug_text != text:\n",
    "                augmented_texts.append(aug_text)\n",
    "        except:\n",
    "            continue\n",
    "    return augmented_texts\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AUGMENTING MINORITY CLASSES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "negative_df = df[df['airline_sentiment'] == 'negative']\n",
    "neutral_df = df[df['airline_sentiment'] == 'neutral']\n",
    "positive_df = df[df['airline_sentiment'] == 'positive']\n",
    "\n",
    "max_count = len(negative_df)\n",
    "\n",
    "neutral_needed = max_count - len(neutral_df)\n",
    "positive_needed = max_count - len(positive_df)\n",
    "\n",
    "print(f\"\\nAugmentation targets:\")\n",
    "print(f\"  • Neutral class:  {len(neutral_df):,} → {max_count:,} (need {neutral_needed:,} more)\")\n",
    "print(f\"  • Positive class: {len(positive_df):,} → {max_count:,} (need {positive_needed:,} more)\")\n",
    "\n",
    "augmented_data = []\n",
    "\n",
    "print(f\"\\n⏳ Augmenting neutral class...\")\n",
    "neutral_samples = neutral_df.sample(n=neutral_needed, replace=True, random_state=42)\n",
    "for idx, row in enumerate(neutral_samples.itertuples(), 1):\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"   Processed {idx}/{neutral_needed}...\")\n",
    "    \n",
    "    augmenter = aug_synonym \n",
    "    # if idx % 2 == 0 else aug_insert\n",
    "    aug_texts = augment_text(row.text, augmenter, num_augmentations=1)\n",
    "    \n",
    "    if aug_texts:\n",
    "        augmented_data.append({\n",
    "            # 'cleaned_text': aug_texts[0],\n",
    "            'airline_sentiment': row.airline_sentiment,\n",
    "            # 'airline': row.airline,\n",
    "            'text': f\"{row.text}\"\n",
    "        })\n",
    "\n",
    "print(f\"✓ Neutral class augmented: {len([d for d in augmented_data if d['airline_sentiment'] == 'neutral'])} new samples\")\n",
    "\n",
    "print(f\"\\n⏳ Augmenting positive class...\")\n",
    "positive_samples = positive_df.sample(n=positive_needed, replace=True, random_state=42)\n",
    "for idx, row in enumerate(positive_samples.itertuples(), 1):\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"   Processed {idx}/{positive_needed}...\")\n",
    "    \n",
    "    augmenter = aug_synonym \n",
    "    # if idx % 2 == 0 else aug_insert\n",
    "    aug_texts = augment_text(row.text, augmenter, num_augmentations=1)\n",
    "    \n",
    "    if aug_texts:\n",
    "        augmented_data.append({\n",
    "            # 'cleaned_text': aug_texts[0],\n",
    "            'airline_sentiment': row.airline_sentiment,\n",
    "            # 'airline': row.airline,\n",
    "            'text': f\"{row.text}\"\n",
    "        })\n",
    "\n",
    "print(f\"✓ Positive class augmented: {len([d for d in augmented_data if d['airline_sentiment'] == 'positive'])} new samples\")\n",
    "\n",
    "augmented_needed = pd.DataFrame(augmented_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a69cc14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9157\n",
       "neutral     3091\n",
       "positive    2353\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"airline_sentiment\",\"text\"]]\n",
    "\n",
    "df.groupby(\"airline_sentiment\")[\"airline_sentiment\"].count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b326424e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "neutral     6066\n",
       "positive    6804\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_needed.groupby(\"airline_sentiment\")[\"airline_sentiment\"].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "540cd041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate the df with augmented_needed to make new balanced data \n",
    "df_aug = pd.concat([df,augmented_needed], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ef2787c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9157\n",
       "neutral     9157\n",
       "positive    9157\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug.groupby(\"airline_sentiment\")[\"airline_sentiment\"].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5b2f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ycode\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ycode\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ycode\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Téléchargez les ressources NLTK nécessaires si ce n'est pas déjà fait\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68577785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                what said\n",
      "1        plus youve added commercials to the experience...\n",
      "2        i didnt today must mean i need to take another...\n",
      "3        its really aggressive to blast obnoxious enter...\n",
      "4                  and its a really big bad thing about it\n",
      "                               ...                        \n",
      "12865    luv ya too i will sing a song for yall when i ...\n",
      "12866    has getaway deals through may from 59 oneway l...\n",
      "12867    already booked my tickets for august 20th30th ...\n",
      "12868    great cabin and flight crew this morning on a ...\n",
      "12869    thank you for your help adam and to the awesom...\n",
      "Name: text_normalized, Length: 27471, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_aug[\"text_normalized\"] = (\n",
    "df_aug[\"text\"]\n",
    ".str.lower()                                   # minuscules\n",
    ".str.replace(r'http\\S+|www\\S+', '', regex=True) # suppression des URLs\n",
    ".str.replace(r'@\\w+', '', regex=True)           # suppression des mentions\n",
    ".str.replace(r'#\\w+', '', regex=True)           # suppression des hashtags\n",
    ".str.replace(r'[^a-z0-9\\s]', '', regex=True)    # ponctuation & caractères spéciaux\n",
    ".str.replace(r'\\s+', ' ', regex=True)           # espaces multiples → 1 espace\n",
    ".str.strip()                                    # suppression espaces début/fin\n",
    ")\n",
    "\n",
    "print(df_aug[\"text_normalized\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f06b3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def stop_words_remover(text): \n",
    "    tokens = text.split()\n",
    "    tokens_filter = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6497ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug[\"text_normalized\"] = df_aug[\"text_normalized\"].apply(lambda x: stop_words_remover(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c45da",
   "metadata": {},
   "source": [
    "<h1 style=\"color:orange;\"> Generate embedding ! </h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bbfc5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better embedding model (but it's more heavy) \n",
    "# model2 = SentenceTransformer(\"all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65f84aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158ec7b459c4411dbb5ce4fdd08d3b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/859 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding = model.encode(\n",
    "    df_aug[\"text\"].tolist(),\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29d372ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0030891 ,  0.08647377, -0.0453333 , ..., -0.06762812,\n",
       "        -0.00764808, -0.02906491],\n",
       "       [-0.01704391,  0.0413912 ,  0.05309898, ..., -0.07246983,\n",
       "         0.00061238, -0.03143211],\n",
       "       [ 0.01765142, -0.00182621,  0.05536732, ..., -0.08177378,\n",
       "        -0.11430358, -0.04604586],\n",
       "       ...,\n",
       "       [ 0.04800796, -0.0421735 ,  0.03474437, ...,  0.00460419,\n",
       "        -0.06315816, -0.03838864],\n",
       "       [ 0.02445298, -0.01317603,  0.08007919, ...,  0.05164472,\n",
       "        -0.07421819, -0.04779695],\n",
       "       [ 0.02990052, -0.05761112,  0.0138815 , ..., -0.02579542,\n",
       "        -0.05957169, -0.06932101]], shape=(27471, 384), dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to standard lists for ChromaDB compatibility\n",
    "\n",
    "df_aug[\"embedding\"] = embedding.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d508ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug.to_pickle(\"../data/embedded_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
